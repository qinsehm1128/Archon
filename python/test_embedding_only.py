#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„åµŒå…¥æ¨¡å‹æµ‹è¯•è„šæœ¬
è·³è¿‡æ‰€æœ‰æ•°æ®åº“å’Œé…ç½®æ£€æŸ¥ï¼Œç›´æ¥æµ‹è¯• Qwen3-Embedding-0.6B æ¨¡å‹
"""

import asyncio
import sys
import os
import traceback
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

async def test_qwen_embedding():
    """æµ‹è¯• Qwen åµŒå…¥æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
    print("ğŸš€ Starting Qwen3-Embedding-0.6B test...")
    print(f"ğŸ“ Project root: {project_root}")
    print(f"ğŸ Python version: {sys.version}")

    try:
        # ç›´æ¥å¯¼å…¥åµŒå…¥æœåŠ¡
        print("ğŸ“¦ Importing embedding service...")
        from src.server.services.embeddings.embedding_service import create_embedding, create_embeddings_batch

        # æµ‹è¯•å•ä¸ªåµŒå…¥
        print("ğŸ” Testing single embedding...")
        test_text = "This is a test sentence for Qwen embedding model."
        embedding = await create_embedding(test_text)

        print(f"âœ… Single embedding successful!")
        print(f"   - Input text: {test_text[:50]}...")
        print(f"   - Embedding dimensions: {len(embedding)}")
        print(f"   - Sample values: {embedding[:5]}")

        # æµ‹è¯•æ‰¹é‡åµŒå…¥
        print("\nğŸ“ Testing batch embeddings...")
        test_texts = [
            "Hello world, this is a test.",
            "Machine learning with local models is great.",
            "Python and transformers make AI accessible.",
            "Qwen3-Embedding-0.6B is a lightweight model."
        ]

        result = await create_embeddings_batch(test_texts)

        print(f"âœ… Batch embedding successful!")
        print(f"   - Total texts: {len(test_texts)}")
        print(f"   - Successful embeddings: {result.success_count}")
        print(f"   - Failed embeddings: {result.failure_count}")

        if result.embeddings:
            print(f"   - Embedding dimensions: {len(result.embeddings[0])}")
            print(f"   - Sample embedding: {result.embeddings[0][:3]}")

        if result.has_failures:
            print(f"âŒ Some failures occurred:")
            for failure in result.failed_items:
                print(f"   - Error: {failure['error']}")

        print("\nğŸ‰ Qwen embedding model test completed successfully!")
        print("âœ¨ Your local embedding model is working perfectly!")
        return True

    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("ğŸ’¡ This might be a dependency issue. Check if transformers and torch are installed.")
        return False

    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        print("\nğŸ” Full traceback:")
        traceback.print_exc()
        return False

async def test_model_download():
    """æµ‹è¯•æ¨¡å‹ä¸‹è½½å’Œåˆå§‹åŒ–"""
    print("\nğŸ¤– Testing model download and initialization...")

    try:
        from transformers import AutoModel, AutoTokenizer
        import torch

        model_name = "Qwen/Qwen3-Embedding-0.6B"
        cache_dir = "./models"

        print(f"ğŸ“¥ Loading model: {model_name}")
        print(f"ğŸ’¾ Cache directory: {cache_dir}")
        print(f"ğŸ–¥ï¸  Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}")

        # åŠ è½½åˆ†è¯å™¨
        print("ğŸ”¤ Loading tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            cache_dir=cache_dir,
            trust_remote_code=True
        )
        print("âœ… Tokenizer loaded successfully")

        # åŠ è½½æ¨¡å‹
        print("ğŸ§  Loading model...")
        model = AutoModel.from_pretrained(
            model_name,
            cache_dir=cache_dir,
            trust_remote_code=True
        )
        print("âœ… Model loaded successfully")

        # æµ‹è¯•æ¨ç†
        print("ğŸ”„ Testing model inference...")
        test_text = "Hello world"
        inputs = tokenizer(test_text, return_tensors='pt')

        with torch.no_grad():
            outputs = model(**inputs)
            embeddings = outputs[0].mean(dim=1)  # Simple mean pooling

        print(f"âœ… Model inference successful!")
        print(f"   - Input: {test_text}")
        print(f"   - Output shape: {embeddings.shape}")

        return True

    except Exception as e:
        print(f"âŒ Model test failed: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¯ Qwen3-Embedding-0.6B Standalone Test")
    print("=" * 60)

    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['HF_HOME'] = './models'

    # è¿è¡Œæµ‹è¯•
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    try:
        # å…ˆæµ‹è¯•æ¨¡å‹ä¸‹è½½
        model_success = loop.run_until_complete(test_model_download())

        if model_success:
            # å†æµ‹è¯•åµŒå…¥æœåŠ¡
            embedding_success = loop.run_until_complete(test_qwen_embedding())

            if embedding_success:
                print("\nğŸŠ ALL TESTS PASSED! ğŸŠ")
                print("âœ¨ Your Qwen embedding model is ready to use!")
                exit(0)
            else:
                print("\nâŒ Embedding service test failed")
                exit(1)
        else:
            print("\nâŒ Model download/initialization failed")
            exit(1)

    except KeyboardInterrupt:
        print("\nâ¹ï¸  Test interrupted by user")
        exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ Unexpected error: {e}")
        traceback.print_exc()
        exit(1)
    finally:
        loop.close()